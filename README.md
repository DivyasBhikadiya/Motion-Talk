# Motion_Talk

The primary goal of Motion Talk is to recognize and interpret specific gestures or movements made by a person in front of a camera.
In this Motion Talk project I have developed, recognizing keyboard words through gestures involves extending the initial system to interpret gestures as specific keyboard inputs or words.
Also developed an interactive window for Hand gestures and for showing the prediction of keywords.
Tech Stack: Opencv-python, numpy, keras, keyboard
